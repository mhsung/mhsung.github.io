---
title:  "Compositional Generalizability in Geometry, Physics, and Policy Learning"

presenter: <a href="https://cseweb.ucsd.edu/~haosu/" target="_blank">Hao Su</a>

position: Assistant Professor at UCSD

schedule: Mar 30, 2021 (Tue), 9:00 a.m. KST

google_calendar_link: <a target="_blank" href="https://calendar.google.com/calendar/r/eventedit/copy/dmpodjZjc2pkZWM5NzlldW1wOW1ta2o5aGcgaWEzc2RpanFzcnAzY3NsN2NqaHR0bTU3cDBAZw"><i class="fa fa-calendar" aria-hidden="true"></i> Add to Google Calendar</a>

zoom_link: <a target="_blank" href="https://us02web.zoom.us/j/87000461636"><i class="fa fa-video-camera" aria-hidden="true"></i> Zoom Webinar Link</a>

slug: guest-lecture-hao-su

date: 2021-03-30
---


## {{ page.title }}
{:.title}
### {{ page.presenter }}
{:.title}
#### {{ page.position }}
{:.title}
#### {{ page.schedule }}
{:.title}
<br />

#### Guest Lecture at <a href="{{site.baseurl}}/{{page.path}}/../../" target="_blank">CS492(H) Machine Learning for 3D Data (Spring 2021)</a>, <a href="https://www.kaist.ac.kr/" target="_blank">KAIST</a>.
{:.title}
#### Host: <a href="{{site.baseurl}}/" target="_blank">Minhyuk Sung</a>
{:.title}
<br />

![]({{site.baseurl}}/{{page.path}}/../../images/guest-lecture-hao-su.png)
<br />

#### {{ page.google_calendar_link }}
{:.title}
#### {{ page.zoom_link }}
{:.title}

### Abstract
It is well known that deep neural networks are universal function approximators and have good generalizability when the training and test datasets are sampled from the same distribution. Most deep-learning-based applications and theories in the past decade are based upon this setup. While the view of learning function approximators has been rewarding to the community, we are seeing more and more of its limitations when dealing with the real-world problem space that is combinatorially exploded. In this talk, I will discuss a possible shift of view, from learning function approximators to learning algorithm approximators, by some preliminary work in my lab. Our ultimate goal is to achieve generalizability when learning in a problem space of combinatorial complexity. We refer to this desired generalizability as compositional generalizability. To this goal, we take important problems in geometry, physics, and policy learning as testbeds. Particularly, I will introduce how we build algorithms with state-of-the-art compositional generalizability on these testbeds, following a bottom-up principle and a modularized principle.
<br />

### Bio
Hao Su is an Assistant Professor of Computer Science and Engineering in UC San Diego. He is interested in fundamental problems in broad disciplines related to artificial intelligence, including machine learning, computer vision, computer graphics, and robotics. His most recent work focuses on integrating the disciplines for building and training embodied AI that can interact with the physical world. In the past, his work of ShapeNet, PointNet series, and graph neural networks have significantly impacted the emergence and growth of a new field, 3D deep learning. He also used to participate in the development of ImageNet, a large-scale 2D image database. He has served as the Area Chair, Associated Editor, and other comparable positions in the program committee of CVPR, ICCV, ECCV, ICRA, Transactions on Graphics (TOG), and AAAI.
<br />

<br />

